{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras,os,random, pickle, hdf5storage, \n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TENSORFLOW_FLAGS\"]  = \"device=gpu%d\"%(1)\n",
    "import keras\n",
    "import hdf5storage\n",
    "from keras.models import Sequential\n",
    "import scipy.io as sio\n",
    "import array \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import losses\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from IPython.display import clear_output\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "from keras import regularizers"
   ]
  },
  # Dataset
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Sigfox','LoRA_SF7','LoRA_SF12','IEEE802.15.4g','noise']\n",
    "in_dim=[2,500]\n",
    "num_classes=5\n",
    "load_data = hdf5storage.loadmat('combined_data_normalize_mapstd_snr_0to35_test.mat')\n",
    "X = load_data['combine_data']\n",
    "X_label=load_data['combine_data_label']\n",
    "X_labeld = keras.utils.to_categorical(X_label,num_classes)\n",
    "X_labeld = np.reshape(X_labeld,(300000,5))\n",
    "[r_comb,c_comb]=X.shape\n",
    "X=np.reshape(X,(int(r_comb),2,int(c_comb/2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2018)\n",
    "n_examples = X.shape[0]\n",
    "n_train = n_examples * 0.6\n",
    "train_idx = np.random.choice(range(0,n_examples), size=int(n_train), replace=False)\n",
    "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
    "X_train = X[train_idx]\n",
    "X_test =  X[test_idx]\n",
    "X_train_label=X_labeld[train_idx]\n",
    "X_test_label=X_labeld[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 2, 500, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 6, 504, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 6, 502, 64)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 502, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 251, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 251, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 2, 249, 40)        15400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 249, 40)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 124, 40)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 124, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4960)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 100)               496100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 5)                 505       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 512,677\n",
      "Trainable params: 512,469\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan Shahid\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, kernel_initializer=\"he_normal\", name=\"dense1\", kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
      "C:\\Users\\Adnan Shahid\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"he_normal\", name=\"dense2\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "dr = 0.35\n",
    "model = Sequential()\n",
    "model.add(Reshape(in_dim+[1],input_shape=in_dim))\n",
    "model.add(ZeroPadding2D((2, 2)))\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(64, (1, 3), kernel_regularizer=regularizers.l2(0.01), name='conv1', padding='valid', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(dr))\n",
    "# 2nd convolutional layer\n",
    "model.add(Conv2D(40, (2, 3), kernel_regularizer=regularizers.l2(0.01), name='conv2', padding='valid', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(dr))\n",
    "# 3rd convolutional layer\n",
    "#model.add(Conv2D(40, (2, 3), name='conv3', padding='valid', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "##model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Dropout(dr))\n",
    "# Fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, kernel_regularizer=regularizers.l2(0.01), activation='relu', init='he_normal', name=\"dense1\"))\n",
    "model.add(Dropout(dr))\n",
    "#Fully connected final layer\n",
    "model.add(Dense(len(classes), kernel_regularizer=regularizers.l2(0.01), init='he_normal', name=\"dense2\" ))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Reshape([len(classes)]))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "  1664/180000 [..............................] - ETA: 1:03:12 - loss: 4.8914 - acc: 0.2686"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "batch_size = 128\n",
    "early_stop=keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "filepath='sigfox_loRA_SF7and12_ieee802.15.4_noise_normalize_mapstd_snr_-10to40_fft.h5'\n",
    "plot_losses=PlotLosses()\n",
    "history = model.fit(X_train, X_train_label,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, X_test_label),callbacks=[plot_losses,early_stop,keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')])\n",
    "#early_stop,keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')]\n",
    "model.load_weights(filepath)\n",
    "\n",
    "#model.load_weights(filepath)\n",
    "\n",
    "score = model.evaluate(X_test, X_test_label, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#model.save('sigfox_loRA_SF7and12_ieee802.15.4_noise_normalize_mapstd_snr_0to45_model_save.h5') \n",
    "\n",
    " #Show loss curves \n",
    "plt.figure()\n",
    "plt.title('Training performance')\n",
    "plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='val_error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
